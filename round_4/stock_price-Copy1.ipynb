{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 주식 가격 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import xgboost\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read train data\n",
    "with open('./data/train_data.json') as fp:\n",
    "    json_str = fp.read()\n",
    "    json_data = json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(json_data, columns=['date','name','open','close','low','high','vol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/grading.input.txt') as fp:\n",
    "    sbm_in = fp.read()\n",
    "    sbm_in = sbm_in.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 counts name:  teller . Length of y:  249\n",
      "50 counts name:  speeders . Length of y:  1760\n",
      "100 counts name:  hairs . Length of y:  1760\n",
      "150 counts name:  thyristors . Length of y:  1760\n",
      "200 counts name:  jurisdictions . Length of y:  1760\n",
      "250 counts name:  anchors . Length of y:  1760\n",
      "300 counts name:  shovels . Length of y:  1760\n",
      "350 counts name:  tab . Length of y:  1760\n",
      "400 counts name:  tires . Length of y:  1760\n",
      "450 counts name:  similarity . Length of y:  1760\n",
      "500 counts name:  leaf . Length of y:  124\n"
     ]
    }
   ],
   "source": [
    "# teller_df = train_df[train_df['name']=='teller']\n",
    "pred_lst = []\n",
    "total = 0\n",
    "true_t = 0\n",
    "for idx, name in enumerate(sbm_in[:]):\n",
    "\n",
    "    teller_df = train_df[train_df['name']==name][:]\n",
    "    teller_df = teller_df.set_index('date')\n",
    "\n",
    "    teller_df['hl_pct'] = (teller_df['high'] - teller_df['low'])/(teller_df['low']*100)\n",
    "    teller_df['pct_chng'] = (teller_df['close'] - teller_df['open'])/(teller_df['open']*100)\n",
    "\n",
    "\n",
    "\n",
    "    # 예측 컬럼\n",
    "    forecast_col = 'close'\n",
    "    # 예측 기간 하루\n",
    "    forecast_out = int(1)\n",
    "    # forecast_out에 맞춰 label을 변경\n",
    "    teller_df['label'] = teller_df[forecast_col].shift(-forecast_out)\n",
    "    # 방향 예측을 위한 전처리\n",
    "    teller_df['direction'] = teller_df['label'] >= teller_df['close']\n",
    "\n",
    "    # X, y\n",
    "    X = teller_df[['close','hl_pct','pct_chng']]\n",
    "    X = preprocessing.scale(X)\n",
    "    X_forecast_out = X[-forecast_out:]\n",
    "    X = X[:-forecast_out]\n",
    "\n",
    "    y = np.array(teller_df['label'])\n",
    "    y = y[:-forecast_out]\n",
    "    y_d = np.array(teller_df['direction'])\n",
    "    y_d = y_d[:-forecast_out]\n",
    "\n",
    "    if idx % 50 == 0:\n",
    "        print(idx,'counts name: ',name, '. Length of y: ', len(y))\n",
    "    \n",
    "    model = SVR(kernel='linear',C=0.01).fit(X,y)\n",
    "    #model = LinearRegression().fit(X,y)\n",
    "    model_d = LogisticRegression(C=0.1).fit(X,y_d)\n",
    "    #model_d = xgboost.XGBClassifier(n_estimators=100,max_depth=7).fit(X,y_d)\n",
    "    y_pred = model.predict(X_forecast_out)\n",
    "    y_d_pred = model_d.predict(X_forecast_out)\n",
    "\n",
    "    if y_d_pred:\n",
    "        val = '+'\n",
    "    else:\n",
    "        val = '-'\n",
    "   # val = '+'\n",
    "    val += ' ' + str(float(y_pred))\n",
    "\n",
    "    pred_lst.append(str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# valid 채점용 데이터\n",
    "with open('price_rst.txt') as fp:\n",
    "    price_rst = fp.read()\n",
    "    price_rst = price_rst.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35031846,  0.30391264,  0.34576887], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_d.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.6726136633497"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(pred_lst)):\n",
    "    pred_lst[i] = pred_lst[i].split(' ')\n",
    "    \n",
    "for i in range(len(price_rst)):\n",
    "    price_rst[i] = price_rst[i].split(' ')\n",
    "\n",
    "valid_df = pd.concat([pd.DataFrame(pred_lst), pd.DataFrame(price_rst)], axis=1)\n",
    "valid_df.columns =['pred_0','pred_1','true_0','true_1']\n",
    "\n",
    "valid_df['s2_1'] = 5-(valid_df['pred_1'].map(float) - valid_df['true_1'].map(float))**2\n",
    "valid_df['s2'] = valid_df['s2_1'].map(lambda x: 0 if x <= 0 else x)\n",
    "\n",
    "valid_df['s1'] = valid_df['pred_0'] == valid_df['true_0']\n",
    "valid_df['s1'] = valid_df['s1'].map(lambda x: 5 if x == True else 0)\n",
    "\n",
    "valid_df['score'] = valid_df['s1']+valid_df['s2']\n",
    "\n",
    "10*valid_df['score'].sum()/len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.27141605855927"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yoo/Desktop/elice/round_4\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "# 73.2714\n",
    "output_file = 'submission.txt'\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    for _test_pred in pred_lst:\n",
    "        fp.write(_test_pred)\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1343.0829117246076\n"
     ]
    }
   ],
   "source": [
    "print('rmse: {}'.format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.912 54.4608268379\n",
      "115.115 54.4014640812\n",
      "70.356 49.654247328\n",
      "22.48 53.6749650498\n",
      "156.512 58.9931905539\n",
      "37.36 51.7156741119\n",
      "48.873 52.7771904789\n",
      "62.408 53.7650887306\n",
      "61.211 50.6574986059\n",
      "138.516 54.4643328079\n",
      "126.36 55.0027553166\n",
      "31.89 53.7229694809\n",
      "54.82 51.7443669807\n",
      "47.695 50.2150099343\n",
      "69.639 54.7606501126\n",
      "70.935 52.2044161391\n",
      "38.447 50.0328951249\n",
      "31.18 55.7271108202\n",
      "59.315 50.4827361197\n",
      "55.674 51.5835367604\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(y_test[i], y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  randomforest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_2 = RandomForestClassifier(n_estimators=200, max_depth=6).fit(X_train, y_d_train)\n",
    "model_2 = LogisticRegression(C=0.1).fit(X_train, y_d_train) # 0.62\n",
    "#model_2 = LinearSVC(C=0.02).fit(X_train,y_d_train) # 0.01 -> 0.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_d_pred = model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51136363636363635"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_d_test, y_d_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116,  57],\n",
       "       [115,  64]], dtype=int64)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_d_test,y_d_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_x = train_df[['date']][train_df['name']==sbm_in[-1]]\n",
    "t_x = t_x['date'].map(lambda x: ''.join(x.split('-')))\n",
    "t_y = train_df[['close']][train_df['name']==sbm_in[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(t_x, t_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_rst =[]\n",
    "for i in range(501)[:]:\n",
    "    before_price = float(train_df[['close']][train_df['name'] ==sbm_in[i]].iloc[-2])\n",
    "    true_price = float(train_df[['close']][train_df['name'] ==sbm_in[i]].iloc[-1])\n",
    "    \n",
    "    if true_price > before_price:\n",
    "        val = '+'\n",
    "    else:\n",
    "        val = '-'\n",
    "        \n",
    "    val += ' '+ str(true_price)\n",
    "    price_rst.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = 'price_rst.txt'\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    for _test_pred in price_rst:\n",
    "        fp.write(_test_pred)\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      hairs\n",
       "close    24.701\n",
       "Name: 850362, dtype: object"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(price_rst).iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'teller'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_lst = [] \n",
    "for idx, name in enumerate(sbm_in):\n",
    "    price_lst.append(tr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "rst = []\n",
    "for idx, name in enumerate(sbm_in):\n",
    "    dates = train_df[train_df['name'] == name]['date']\n",
    "    dates = dates.map(lambda x : int(''.join(x.split('-'))))\n",
    "    prices = train_df[train_df['name'] == name]['close']\n",
    "\n",
    "    prices = np.reshape(prices,[-1,1])\n",
    "    dates = np.reshape(dates,[-1,1])\n",
    "\n",
    "    lst.append(SVR(kernel='rbf',C=1e3).fit(dates,prices))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    pred = float(lst[idx].predict(20171230))\n",
    "    \n",
    "    if pred > prices[-1]:\n",
    "        row = '+'\n",
    "    else: \n",
    "        row = '-'\n",
    "    \n",
    "    row += ' ' + str(pred)\n",
    "    rst.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission\n",
    "\n",
    "output_file = 'submission.txt'\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    for _test_pred in rst:\n",
    "        fp.write(_test_pred)\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/elice/data/grading.input.txt') as fp:\n",
    "    sbm_in = fp.read()\n",
    "    sbm_in = sbm_in.splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['teller', 'winch', 'bay', 'admissions', 'mules', 'horizons',\n",
       "       'gross', 'residues', 'null', 'flake'], dtype=object)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['name'].unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['teller',\n",
       " 'winch',\n",
       " 'bay',\n",
       " 'admissions',\n",
       " 'mules',\n",
       " 'firearms',\n",
       " 'horizons',\n",
       " 'gross',\n",
       " 'residues',\n",
       " 'null']"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbm_in[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>teller</td>\n",
       "      <td>123.677</td>\n",
       "      <td>125.591</td>\n",
       "      <td>122.459</td>\n",
       "      <td>126.181</td>\n",
       "      <td>2163918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    name     open    close     high      low      vol\n",
       "0  2016-01-05  teller  123.677  125.591  122.459  126.181  2163918"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in lst:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 122.641])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 122.7410345])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_t.predict(20161228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>teller</td>\n",
       "      <td>123.677</td>\n",
       "      <td>125.591</td>\n",
       "      <td>122.459</td>\n",
       "      <td>126.181</td>\n",
       "      <td>2163918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>teller</td>\n",
       "      <td>125.134</td>\n",
       "      <td>120.089</td>\n",
       "      <td>120.067</td>\n",
       "      <td>125.768</td>\n",
       "      <td>2382872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>teller</td>\n",
       "      <td>116.413</td>\n",
       "      <td>114.925</td>\n",
       "      <td>114.670</td>\n",
       "      <td>119.469</td>\n",
       "      <td>2488061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    name    start      end      min      max      vol\n",
       "0  2016-01-05  teller  123.677  125.591  122.459  126.181  2163918\n",
       "1  2016-01-06  teller  125.134  120.089  120.067  125.768  2382872\n",
       "2  2016-01-07  teller  116.413  114.925  114.670  119.469  2488061"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read train data\n",
    "with open('./data/train_data.json') as fp:\n",
    "    json_str = fp.read()\n",
    "    json_data = json.loads(json_str)\n",
    "    \n",
    "# convert to dataframe\n",
    "train_df = pd.DataFrame(json_data)\n",
    "\n",
    "# train data preprocessing\n",
    "train_df['rating_cat'] = train_df['rating'].apply(lambda x: \n",
    "                    'NEG' if 1<= x <=3 \n",
    "                     else \n",
    "                      ('NEU' if 4<=x<=7 \n",
    "                     else 'POS'))\n",
    "\n",
    "# read test data in/out\n",
    "with open('./data/test.input') as fp:\n",
    "    test_in = fp.read()\n",
    "    test_in = test_in.splitlines()\n",
    "\n",
    "with open('./data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Converting text to vector with Tfid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorize train using Tfid(bag of words)\n",
    "\n",
    "twitter = Twitter()\n",
    "\n",
    "def tokenize_pos(doc):\n",
    "    return ['/'.join(t) for t in twitter.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), use_idf=False, smooth_idf=False)\n",
    "\n",
    "\n",
    "y = train_df.rating_cat\n",
    "X = vectorizer.fit_transform(train_df.review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting & validtaion check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776547619048\n"
     ]
    }
   ],
   "source": [
    "# fitting train data with classifier\n",
    "\n",
    "model = SGDClassifier(alpha=1.9e-6, n_iter=19).fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "# predict test data\n",
    "feature_list = vectorizer.get_feature_names()\n",
    "\n",
    "test_vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), vocabulary = feature_list)\n",
    "X_test = test_vectorizer.fit_transform(test_in[:8400])\n",
    "\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "print(accuracy_score(test_out[:8400], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.77178571  0.77535714  0.775       0.7747619   0.77309524]\n",
      " [ 0.77535714  0.77488095  0.77428571  0.775       0.77452381]\n",
      " [ 0.77333333  0.77321429  0.77464286  0.7747619   0.77547619]\n",
      " [ 0.77607143  0.77202381  0.77404762  0.77345238  0.77357143]\n",
      " [ 0.77285714  0.77345238  0.77440476  0.77404762  0.77511905]\n",
      " [ 0.77607143  0.77452381  0.77369048  0.77464286  0.77392857]\n",
      " [ 0.77559524  0.77535714  0.77416667  0.77416667  0.77452381]\n",
      " [ 0.77333333  0.77369048  0.77488095  0.77238095  0.77559524]\n",
      " [ 0.77488095  0.77285714  0.77404762  0.77380952  0.77630952]\n",
      " [ 0.775       0.77380952  0.77607143  0.77404762  0.7752381 ]]\n",
      "[ 0.774       0.77480952  0.77428571  0.77383333  0.77397619  0.77457143\n",
      "  0.7747619   0.77397619  0.77438095  0.77483333]\n"
     ]
    }
   ],
   "source": [
    "# optimizing alpha \n",
    "\n",
    "alpha = np.arange(2.5e-6,3.5e-6,1e-7)\n",
    "\n",
    "ite = 5 #  반복\n",
    "score = np.zeros([len(alpha), ite])\n",
    "\n",
    "for i, val in enumerate(alpha):\n",
    "    for k in range(ite): \n",
    "        model = SGDClassifier(alpha=val).fit(X, y)\n",
    "        test_pred = model.predict(X_test)\n",
    "\n",
    "        score[i][k] = accuracy_score(test_out[:8400], test_pred)\n",
    "        \n",
    "print(score)\n",
    "print(score.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.77559524  0.7752381   0.77428571  0.77428571  0.77380952]\n",
      " [ 0.77583333  0.775       0.77452381  0.77464286  0.775     ]\n",
      " [ 0.77416667  0.77559524  0.7752381   0.77452381  0.77464286]\n",
      " [ 0.77440476  0.77571429  0.77309524  0.77404762  0.77559524]\n",
      " [ 0.77392857  0.77547619  0.77464286  0.77452381  0.77452381]\n",
      " [ 0.77440476  0.7747619   0.7747619   0.77452381  0.77392857]\n",
      " [ 0.7747619   0.7752381   0.7747619   0.77452381  0.77595238]\n",
      " [ 0.77571429  0.7752381   0.77464286  0.77404762  0.77488095]\n",
      " [ 0.77535714  0.77511905  0.77428571  0.77511905  0.77511905]\n",
      " [ 0.77547619  0.77428571  0.77511905  0.775       0.77392857]]\n",
      "[ 0.77464286  0.775       0.77483333  0.77457143  0.77461905  0.77447619\n",
      "  0.77504762  0.77490476  0.775       0.7747619 ]\n"
     ]
    }
   ],
   "source": [
    "# optimizing n-iter \n",
    "\n",
    "n = np.arange(15,25)\n",
    "\n",
    "\n",
    "ite = 5 #  반복\n",
    "score = np.zeros([len(n), ite])\n",
    "\n",
    "\n",
    "for i, val in enumerate(n):\n",
    "    for k in range(ite): \n",
    "        \n",
    "        model = SGDClassifier(alpha=2.9e-6, n_iter=val).fit(X, y)\n",
    "        test_pred = model.predict(X_test)\n",
    "\n",
    "        score[i][k] = accuracy_score(test_out[:8400], test_pred)\n",
    "        \n",
    "print(score)\n",
    "print(score.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SGDClassifier(alpha=2.9e-6, n_iter=21).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission\n",
    "\n",
    "with open('./data/grading.input') as fp:\n",
    "    sbm_in = fp.read()\n",
    "    sbm_in = sbm_in.splitlines()\n",
    "\n",
    "feature_list = vectorizer.get_feature_names()\n",
    "\n",
    "test_vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), vocabulary = feature_list)\n",
    "sbm_test = test_vectorizer.fit_transform(sbm_in[:8400])\n",
    "\n",
    "sbm_pred = model.predict(sbm_test)\n",
    "\n",
    "output_file = 'submission.txt'\n",
    "\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    for _test_pred in sbm_pred:\n",
    "        fp.write(_test_pred)\n",
    "        fp.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
